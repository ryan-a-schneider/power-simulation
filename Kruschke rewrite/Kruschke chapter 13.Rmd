---
title: "Kruschke chapter 13"
output: html_document
---

```{r}
pacman::p_load(tidyverse,janitor, brms, rstanarm, bayestestR, performance, insight, parameters, report, see)
```


# Power from Idealized or Actual Data


## Generating data that represents your best guess of how the real data would turn out.

In practice, it is often more intuitive to specify actual or idealized *data* that express the hypothesis, than it is to specify top-level parameter properties. The idea is that we start with the actual or idealized data and then use Bayes’ rule to generate the corresponding distribution on parameter values. (p. 376, emphasis in the original)

As a simple example, if you were going to generate data that you thought would represent tosses of a fair die, you'd have a mean of 3.5 (because that's the long-run expected average of a 1d6) and some standard deviation to match. Therefore, your **first step is to generate data that you think best mimics what the real data will turn out to look like**.

In this example, Kruschke uses the study *Therapeutic Touch*, in which practitioners of the "Therapeutic touch" (which is when you wave your hands like a shaman near a patient to redirect/reshape a patient's energy) were tested to see if they could identify which hand of theirs a patient was near (they were blocked from sight). The practicioner had to guess either the left or right hand for each trial; data were scored as right or wrong.

- Model is hierarchical: there are individual abilities, and then group-level abilities that describe all the practitioners (i.e., the overall ability of these practitioners as a whole)



# Step 1

We are going to imagine/hypothesize that the group of practitioners as a whole is correct 65% of the time. That is, they had a 65% probability of correctly detecting which hand was near the patient. Furthermore, individual abilities were within 7% of this (i.e., SD= 7%)

*The ideal group mean is 0.65, and the SD is 0.07*

```{r}
# specify idealized hypothesis:
ideal_group_mean <- 0.65
ideal_group_sd   <- 0.07


# Specify how much data you have to support this hypothesis

ideal_n_subj         <- 100  # more subjects => higher confidence in hypothesis
ideal_n_trl_per_subj <- 100  # more trials => higher confidence in hypothesis

```

These parameters are for binomial data. To parameterize θ in terms of a mean and standard deviation, we need to define the beta_ab_from_mean_sd() function.

```{r}
beta_ab_from_mean_sd <- function(mean, sd) {
  
  if (mean <= 0 | mean >= 1) stop("must have 0 < mean < 1")
  if (sd <= 0) stop("sd must be > 0")
  kappa <- mean * (1 - mean) / sd^2 - 1
  if (kappa <= 0) stop("invalid combination of mean and sd")
  a <- mean * kappa
  b <- (1.0 - mean) * kappa
  return(list(a = a, b = b))
  
}
```


# Step 2

Now generate data consistent with these values using a tidyverse-style workflow.


```{r}
b <- beta_ab_from_mean_sd(ideal_group_mean, ideal_group_sd)

# make the results reproducible
set.seed(13)

d <-
  # make a subject index and generate random theta values for idealized subjects
  tibble(s     = 1:ideal_n_subj,
         theta = rbeta(ideal_n_subj, b$a, b$b)) %>% 
  # transform the theta values to exactly match idealized mean and SD
  mutate(theta_transformed = ((theta - mean(theta)) / sd(theta)) * ideal_group_sd + ideal_group_mean) %>% 
  # `theta_transformed` must be between 0 and 1
  mutate(theta_transformed = ifelse(theta_transformed >= 0.999, 0.999,
                                    ifelse(theta_transformed <= 0.001, 0.001,
                                           theta_transformed))) %>% 
  # generate idealized data very close to thetas
  mutate(z = round(theta_transformed * ideal_n_trl_per_subj)) %>% 
  # create vector of 0's and 1's matching the z values generated above
  mutate(y = map(z, ~c(rep(1, .), rep(0, ideal_n_trl_per_subj - .)))) %>% 
  unnest(y)
```


Our main variables are s and y. You can think of the rest as showing our work. Here’s a peek:

```{r}
glimpse(d)
```


# Step 3: Run Bayesian analysis on the idealized data

Fit the data to a hierarchical Logistic Regression to estimate the parameters responsible for this data.

"We are trying to create a set of representative parameter values that can be used for a subsequent power analysis." (Kruschke)

Once you complete this step by running the code, you end up with a posterior distribution of parameter values that you can use for a power analysis. The posterior tells you exactly how much uncertainty should be on each candidate value, given what you think you'll observe in the data.

```{r}
fit13.2 <-
  brm(data = d,
      family = bernoulli(link = logit),
      y ~ 1 + (1 | s),
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 1), class = sd)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 13)
      #file = "fits/fit13.02")
```

Make sure that model has converged and the ESS is good before moving on
```{r}

```

If this is good, then check out your parameters!

```{r}
posterior_samples(fit13.2) %>% 
  pivot_longer(b_Intercept:sd_s__Intercept) %>% 
  
  ggplot(aes(x = value, y = 0)) +
  stat_histinterval(point_interval = mode_hdi, .width = .95,
                    fill = ce[3], color = ce[9],
                    breaks = 40, normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Remember, these are in the log-odds metric.",
       x = NULL) +
  facet_wrap(~ name, scales = "free")
```

Congrats! You now have a posterior distribution of parameter values that you can use for a power analysis.

"Now we have a distribution of parameter values consistent with our idealized hypothesis, but we did not have to figure out the top-level constants in the model. We merely specified the idealized tendencies in the data and expressed our confidence by its amount....So we now have a large set of representative parameter values for conducting power analysis." (Kruschke, pp. 378-79)




Create a function called 'sample_data' that samples $\theta$ values for n subjects, and then uses those values to sample n draws from the corresponding Bernoulli distribution.


```{r}
sample_data <- function(seed, n_subj, n_trial) {
  
  set.seed(seed)
  
  bind_cols(s = 1:n_subj,
            sample_n(f, size = n_subj, replace = T)) %>% 
    mutate(y = map(theta, rbinom, n = n_trial, size = 1)) %>% 
    unnest(y)
  
}

# test it out
sample_data(seed = 13, n_subj = 3, n_trial = 3)


# use this function to generate several data sets and stuff them all into a nested tibble
tibble(seed = 1:4) %>% 
  mutate(data = map(seed, sample_data, n_subj = 14, n_trial = 47))
```


Doing things in a similar manner, Kruschke...
"...ran the power analysis twice, using different selections of subjects and trials. In both cases there [was] a total of 658 trials, but in the first case there [were] 14 subjects with 47 trials per subject, and in the second case there [were] seven subjects with 94 trials per subject." (p. 381)


Before running the simulations in full, we fit the model once and save that fit to iteratively reuse with 'update()'

```{r}
# how many subjects should we have?
n_subj <- 14

# how many trials should we have?
n     <- 47

# fit that joint
fit13.3 <-
  brm(data = sample_theta(seed = 13, n_subj = 14) %>% 
        mutate(y = map(theta, rbinom, n = n, size = 1)) %>% 
        unnest(y),
      family = bernoulli(link = logit),
      y ~ 1 + (1 | s),
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 1), class = sd)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 13,
      control = list(adapt_delta = .9),
      file = "fits/fit13.03")
```


## Step 4: Assessing goal achievement

The specific goal for achieving precision here is considered both at the individual level and the group level.

At the group level:
- The goal is for the 95% HDI on the group mode ($\omega$) to fall above the ROPE around the null value, and for the ROPE's width to be <.2.

At the individual level:
- The goals are (1) for at least one of the $\theta_ss$ 95% HDIs to exceed the ROPE, with none that fall below the ROPE, and (2) for all the $\theta_ss$ 95% HDIs to have widths <.2.

"Now since we used an aggregated binomial model, we don’t have a population-level ω parameter. Rather, we have a population θ. So like before, our first goal is for the population θ to fall above the range [.48,.52]. The second corresponding width goal is also like before; we want θ to have a width of less than 0.2. But since our aggregated binomial model parameterized θ in the log-odds metric, we’ll have to update our get_hdi() function, which we’ll strategically rename 'get_theta_hdi()'" (Kurz)

```{r}
get_theta_hdi <- function(fit) {
  
  fit %>% 
    posterior_samples() %>% 
    transmute(theta = inv_logit_scaled(b_Intercept)) %>% 
    mode_hdi() %>% 
    select(.lower:.upper)
  
}

# how does it work?
get_theta_hdi(fit13.3)
```


As for the individual-level goals, the two Kruschke outlined in the text apply to our model in a straightforward way. But we will need one more custom function designed to pull the θss for the θss. Let’s call this one get_theta_s_hdi().

```{r}
get_theta_s_hdi <- function(fit) {
  
  n_col <-
    coef(fit, summary = F)$s[, , "Intercept"] %>% 
    ncol()
    
  coef(fit, summary = F)$s[, , "Intercept"] %>% 
    data.frame() %>% 
    set_names(1:n_col) %>% 
    mutate_all(inv_logit_scaled) %>% 
    gather(s, value) %>% 
    mutate(s = as.numeric(s)) %>% 
    group_by(s) %>% 
    mode_hdi(value) %>% 
    select(s, .lower:.upper) %>% 
    rename(.lower_s = .lower,
           .upper_s = .upper)
  
}

# how does it work?
get_theta_s_hdi(fit13.3)
```

With sim2, we avoided saving our model brms::brm() fit objects by using map(data, ~update(fit1, newdata = list(y = .)) %>% get_hdi()). That is, within the purrr::map() function, we first used update() to update the fit to the new data and then pumped that directly into get_hdi(), which simply returned our intervals. Though slick, this approach won’t work here because we want to pump our updated model fit into two functions, both get_theta_hdi() and get_theta_s_hdi(). Our work-around will be to make a custom function that updates the fit, saves it as an object, inserts that fit object into both get_theta_hdi() and get_theta_s_hdi(), binds their results together, and the only returns the intervals. We’ll call this function fit_then_hdis()



```{r}
fit_then_hdis <- function(data, seed) {
  
  fit <- update(fit13.3, 
                newdata = data, 
                seed = seed)
  
  cbind(get_theta_hdi(fit),
        get_theta_s_hdi(fit))
}
```


# SIMULATE!!!

```{r}
# how many subjects should we have?
n_subj <- 14

# how many trials should we have?
n_trial <- 47

# how many simulations would you like?
n_sim <- 100

sim3 <-
  tibble(seed = 1:n_sim) %>% 
  mutate(data = map(seed, sample_data, n_subj = n_subj, n_trial = n_trial)) %>% 
  mutate(hdi = map2(data, seed, fit_then_hdis))





sim3 <-
  sim3 %>% 
  unnest(hdi) %>%
  # here we determine whether we passed at the group level
  mutate(pass_rope_theta  = .lower > .52 | .upper < .48,
         pass_width_theta = (.upper - .lower) < .2) %>% 
  # the s-level thetas require two steps.
  # first, we'll outline the three criteria
  mutate(exceed_rope_theta_s  = .lower_s > .52,
         below_rope_theta_s   = .upper_s < .48,
         narrow_width_theta_s = (.upper_s - .lower_s) < .2) %>% 
  # second, we'll evaluate those criteria by group
  group_by(seed) %>% 
  mutate(pass_rope_theta_s  = sum(exceed_rope_theta_s) > 0 & sum(below_rope_theta_s) == 0,
         pass_width_theta_s = mean(narrow_width_theta_s) == 1) %>% 
  ungroup()

head(sim3)
```


# Summarize the results

```{r}
sim3 %>% 
  summarise(power_rope_theta  = mean(pass_rope_theta),
            power_width_theta = mean(pass_width_theta))

sim3 %>% 
  summarise(power_rope_theta_s  = mean(pass_rope_theta_s),
            power_width_theta_s = mean(pass_width_theta_s))
```



# THE SUPER TL;DR VERSION

```{r}


# how many subjects should we have?
n_subj <- 7

# how many trials should we have?
n_trial <- 94

# how many simulations would you like?
n_sim <- 100

sim4 <-
  tibble(seed = 1:n_sim) %>% 
  mutate(data = map(seed, sample_data, n_subj = n_subj, n_trial = n_trial)) %>%
  mutate(hdi = map2(data, seed, fit_then_hdis))


# Wrangle before summarizing
sim4 <-
  sim4 %>% 
  unnest(hdi) %>%
  mutate(pass_rope_theta  = .lower > .52 | .upper < .48,
         pass_width_theta = (.upper - .lower) < .2) %>% 
  mutate(exceed_rope_theta_s  = .lower_s > .52,
         below_rope_theta_s   = .upper_s < .48,
         narrow_width_theta_s = (.upper_s - .lower_s) < .2) %>% 
  group_by(seed) %>% 
  mutate(pass_rope_theta_s  = sum(exceed_rope_theta_s) > 0 & sum(below_rope_theta_s) == 0,
         pass_width_theta_s = mean(narrow_width_theta_s) == 1) %>% 
  ungroup()

#summarize
sim4 %>% 
  summarise(power_rope_theta  = mean(pass_rope_theta),
            power_width_theta = mean(pass_width_theta))
sim4 %>% 
  summarise(power_rope_theta_s  = mean(pass_rope_theta_s),
            power_width_theta_s = mean(pass_width_theta_s))

```







